{"cells":[{"cell_type":"markdown","metadata":{"id":"rfQLdwVLfahD"},"source":["<center><a href=\"https://www.nvidia.com/dli\"> <img src=\"https://drive.google.com/uc?id=1J3bpGyJcz-7uOFkUNhvOBiReBCk-sUwR\" width=\"200\" </a></center>"]},{"cell_type":"markdown","source":["#Conectando com Google Drive"],"metadata":{"id":"JacysjUcfmde"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTfKpA66frJJ","executionInfo":{"status":"ok","timestamp":1699269144196,"user_tz":180,"elapsed":107581,"user":{"displayName":"Mariana Marinho da Silva Andrade","userId":"11761712930940149369"}},"outputId":"a3813922-695a-412d-f533-b1c38dd2437b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/Colab Notebooks/Projeto CNN\n","\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnT98EqwftY5","executionInfo":{"status":"ok","timestamp":1699269145052,"user_tz":180,"elapsed":860,"user":{"displayName":"Mariana Marinho da Silva Andrade","userId":"11761712930940149369"}},"outputId":"cfd4780f-dd95-43f5-bd9f-192c7e6f4e80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/gdrive/MyDrive/Colab Notebooks/Projeto - CNN'\n","/content\n","gdrive\tsample_data\n"]}]},{"cell_type":"markdown","metadata":{"id":"Cu0vN-QIfahI"},"source":["# Redes Neurais Convolutionais"]},{"cell_type":"markdown","metadata":{"id":"3hfTHQfgfahK"},"source":["Na seção anterior, construímos e treinamos um modelo simples para classificar imagens ASL. O modelo foi capaz de aprender como classificar corretamente o conjunto de dados de treinamento com precisão muito alta, mas não teve um desempenho tão bom no conjunto de dados de validação. Esse comportamento de não generalizar bem para dados que não são de treinamento é chamado de [overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html) e nesta seção apresentaremos um tipo popular de modelo chamado [rede neural convolucional](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) que é especialmente bom para ler imagens e classificá-las."]},{"cell_type":"markdown","metadata":{"id":"u6Nw-o39fahL"},"source":["## Tarefas"]},{"cell_type":"markdown","metadata":{"id":"3u5gYYaBfahL"},"source":["* Prepare dados especificamente para uma CNN\n","* Crie um modelo CNN mais sofisticado, compreendendo uma maior variedade de camadas do modelo\n","* Treine um modelo CNN e observe seu desempenho"]},{"cell_type":"markdown","metadata":{"id":"ooGDTzq6fahM"},"source":["## Carregando e preparando os dados"]},{"cell_type":"markdown","metadata":{"id":"hex8Mx8KfahN"},"source":["A célula abaixo contém as técnicas de pré-processamento de dados, Execute-o antes de prosseguir:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6n2etmX9fahO","colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"status":"error","timestamp":1699269150286,"user_tz":180,"elapsed":5237,"user":{"displayName":"Mariana Marinho da Silva Andrade","userId":"11761712930940149369"}},"outputId":"c3ee5134-6578-446d-f4ce-1f0049c77ebf"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-f6f1503a8485>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load in our data from CSV files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sign_mnist_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvalid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sign_mnist_valid.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sign_mnist_train.csv'"]}],"source":["import tensorflow.keras as keras\n","import pandas as pd\n","\n","# Load in our data from CSV files\n","train_df = pd.read_csv(\"sign_mnist_train.csv\")\n","valid_df = pd.read_csv(\"sign_mnist_valid.csv\")\n","\n","# Separate out our target values\n","y_train = train_df['label']\n","y_valid = valid_df['label']\n","del train_df['label']\n","del valid_df['label']\n","\n","# Separate out our image vectors\n","x_train = train_df.values\n","x_valid = valid_df.values\n","\n","# Turn our scalar targets into binary categories\n","num_classes = 24\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_valid = keras.utils.to_categorical(y_valid, num_classes)\n","\n","# Normalize our image data\n","x_train = x_train / 255\n","x_valid = x_valid / 255"]},{"cell_type":"markdown","metadata":{"id":"fOmD22_7fahQ"},"source":["## Remodelando (Reshaping)  das Imagens para uma CNN"]},{"cell_type":"markdown","metadata":{"id":"GrFa7VDtfahQ"},"source":["As imagens individuais do nosso conjunto de dados estão no formato de longas listas de 784 pixels:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pqmjUMV6fahR"},"outputs":[],"source":["x_train.shape, x_valid.shape"]},{"cell_type":"markdown","metadata":{"id":"7EnwsZ7TfahR"},"source":["Neste formato, não temos todas as informações sobre quais pixels estão próximos uns dos outros. Por causa disso, não podemos aplicar convoluções que detectem recursos. Vamos remodelar nosso conjunto de dados para que fiquem no formato de 28x28 pixels. Isso permitirá que nossas convoluções associem grupos de pixels e detectem recursos importantes.\n","\n","Observe que para a primeira camada convolucional do nosso modelo, precisamos ter não apenas a altura e a largura da imagem, mas também o número de [canais de cores](https://www.photoshopessentials.com/essentials/rgb/) . Nossas imagens estão em tons de cinza, então teremos apenas 1 canal.\n","\n","Isso significa que precisamos converter a forma atual `(27455, 784)` para `(27455, 28, 28, 1)`. Por conveniência, podemos passar ao método [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy.reshape) um `-1` para qualquer dimensão que desejarmos permanecem os mesmos, portanto:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dFEOljivfahS"},"outputs":[],"source":["x_train = x_train.reshape(-1,28,28,1)\n","x_valid = x_valid.reshape(-1,28,28,1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzc9LxlRfahS"},"outputs":[],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gah5lzsXfahT"},"outputs":[],"source":["x_valid.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IwFAtwl0fahT"},"outputs":[],"source":["x_train.shape, x_valid.shape"]},{"cell_type":"markdown","metadata":{"id":"YKbYaOccfahT"},"source":["## Criando um Modelo Convolutional"]},{"cell_type":"markdown","metadata":{"id":"bXJf7seqfahT"},"source":["Hoje em dia, muitos cientistas de dados iniciam seus projetos pegando emprestadas propriedades de modelo de um projeto semelhante. Supondo que o problema não seja totalmente único, há uma grande chance de que as pessoas tenham criado modelos com bom desempenho e que sejam publicados em repositórios on-line como o [TensorFlow Hub](https://www.tensorflow.org/hub) e o [Catálogo NGC ](https://ngc.nvidia.com/catalog/models). Hoje, forneceremos um modelo que funcionará bem para esse problema.\n","\n","<img src=\"https://drive.google.com/uc?id=1WeMvcGJiRLmXCsp6kwozb-7slhHboooq\" width=180 />\n","\n","Abordamos muitos dos diferentes tipos de camadas na palestra e abordaremos todas elas aqui com links para sua documentação. Em caso de dúvida, leia a documentação oficial (ou pergunte ao [stackoverflow](https://stackoverflow.com/))."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tKGJEG1MfahU"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import (\n","    Dense,\n","    Conv2D,\n","    MaxPool2D,\n","    Flatten,\n","    Dropout,\n","    BatchNormalization,\n",")\n","\n","model = Sequential()\n","model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1))) # camada convulocional que soma os pixel\n","model.add(BatchNormalization())\n","model.add(MaxPool2D((2, 2), strides=2, padding=\"same\")) #\n","model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n","model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n","model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n","model.add(Flatten()) # tansforma a matriz em um vetor\n","model.add(Dense(units=512, activation=\"relu\"))\n","model.add(Dropout(0.3)) # desliga 30% dos neuronios de forma aleatoria\n","model.add(Dense(units=num_classes, activation=\"softmax\"))"]},{"cell_type":"markdown","metadata":{"id":"Vi3sOVBSfahU"},"source":["### [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)"]},{"cell_type":"markdown","metadata":{"id":"L9CBgAX6fahV"},"source":["<img src=\"https://drive.google.com/uc?id=1f4iuQX4IBOKW1bCAs9O_MTP-bqBlj-aQ\" largura=300 />\n","\n","Estas são nossas camadas convolucionais 2D. Kernels pequenos examinarão a imagem de entrada e detectarão recursos que são importantes para a classificação. As convoluções anteriores do modelo detectarão recursos simples, como linhas. As convoluções posteriores detectarão recursos mais complexos. Vejamos nossa primeira camada Conv2D:\n","```Python\n","model.add(Conv2D(75 , (3,3) , passadas = 1 , preenchimento = 'mesmo'...)\n","```\n","75 refere-se ao número de filtros que serão aprendidos. (3,3) refere-se ao tamanho desses filtros. Os avanços referem-se ao tamanho do passo que o filtro executará ao passar pela imagem. O preenchimento refere-se a se a imagem de saída criada a partir do filtro corresponderá ao tamanho da imagem de entrada."]},{"cell_type":"markdown","metadata":{"id":"Uia33jJnfahV"},"source":["### [BatchNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) (Normalização em Lotes)"]},{"cell_type":"markdown","metadata":{"id":"_7bMyq71fahV"},"source":["Assim como a normalização de nossas entradas, a normalização em lote dimensiona os valores nas camadas ocultas para melhorar o treinamento. [Leia mais sobre isso em detalhes aqui](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)."]},{"cell_type":"markdown","metadata":{"id":"m-2jg3POfahW"},"source":["### [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)"]},{"cell_type":"markdown","metadata":{"id":"ive0XBTPfahW"},"source":["<img src=\"https://drive.google.com/uc?id=1V0KkSlK9mSrJJLSt6dZM-dN1ciUJJYH2\" width=300 />\n","\n","O Max pooling pega uma imagem e essencialmente a reduz para uma resolução mais baixa. Ele faz isso para ajudar o modelo a ser robusto à translação (objetos movendo-se de um lado para o outro) e também torna nosso modelo mais rápido."]},{"cell_type":"markdown","metadata":{"id":"CnBWEMaxfahW"},"source":["### [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)"]},{"cell_type":"markdown","metadata":{"id":"fGJdMxNyfahW"},"source":["<img src=\"https://drive.google.com/uc?id=1Xd4HFauuDicUANuPu-sgTuUOjJ_Rhnat\" width=360 />\n","\n","Dropout é uma técnica para prevenir overfitting. O dropout seleciona aleatoriamente um subconjunto de neurônios e os desliga, para que eles não participem da propagação direta ou reversa naquela passagem específica. Isso ajuda a garantir que a rede seja robusta e redundante e não dependa de nenhuma área para encontrar respostas."]},{"cell_type":"markdown","metadata":{"id":"tapGTZ9NfahW"},"source":["### [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)"]},{"cell_type":"markdown","metadata":{"id":"MkpwuO-TfahW"},"source":["Flatten pega a saída de uma camada que é multidimensional e a nivela em uma matriz unidimensional. A saída é chamada de vetor de características e será conectada à camada de classificação final."]},{"cell_type":"markdown","metadata":{"id":"aZhmmz69fahW"},"source":["### [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)"]},{"cell_type":"markdown","metadata":{"id":"Zn6e53mOfahX"},"source":["Já vimos camadas densas em nossos modelos anteriores. Nossa primeira camada densa (512 unidades) toma o vetor de recursos como entrada e aprende quais recursos contribuirão para uma classificação específica. A segunda camada densa (24 unidades) é a camada de classificação final que produz nossa previsão."]},{"cell_type":"markdown","metadata":{"id":"LE5-AfR6fahX"},"source":["\n","## Resumo do Modelo"]},{"cell_type":"markdown","metadata":{"id":"QPdk8DOPfahX"},"source":["Isso pode parecer muita informação, mas não se preocupe. Não é fundamental entender tudo agora para treinar modelos convolucionais com eficácia. Mais importante ainda, sabemos que eles podem ajudar na extração de informações úteis de imagens e podem ser usados em tarefas de classificação."]},{"cell_type":"markdown","metadata":{"id":"0H22JvBKfahX"},"source":["Aqui, resumimos o modelo que acabamos de criar. Observe como ele tem menos parâmetros treináveis que o modelo do notebook anterior:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qh9rB2rDfahX"},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"XTbpzgLdfahX"},"source":["## Compilando o Modelo"]},{"cell_type":"markdown","metadata":{"id":"BQNbCeH5fahY"},"source":["Compilaremos o modelo como antes:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKB-v2GjfahY"},"outputs":[],"source":["model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"]},{"cell_type":"markdown","metadata":{"id":"bue-WIwafahY"},"source":["## Treinando o Modelo"]},{"cell_type":"markdown","metadata":{"id":"LMLYGlM0fahY"},"source":["Apesar da arquitetura do modelo muito diferente, o treinamento parece exatamente o mesmo. Execute a célula abaixo para treinar por 20 épocas e vamos ver se a precisão melhora:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sk96bRTAfahY"},"outputs":[],"source":["model.fit(x_train, y_train, epochs=20, verbose=1, validation_data=(x_valid, y_valid))"]},{"cell_type":"markdown","metadata":{"id":"7sGiDc1_fahY"},"source":["## Discussões dos resultados"]},{"cell_type":"markdown","metadata":{"id":"WORBhqOKfahY"},"source":["Parece que este modelo foi significativamente melhorado! A precisão do treinamento é muito alta e a precisão da validação também melhorou. Este é um ótimo resultado, pois tudo o que tivemos que fazer foi trocar por um novo modelo.\n","\n","Você deve ter notado a precisão da validação variando. Isto é uma indicação de que nosso modelo ainda não está generalizando perfeitamente. Felizmente, há mais que podemos fazer. Vamos falar sobre isso na próxima palestra."]},{"cell_type":"markdown","metadata":{"id":"7hGNIQb6fahZ"},"source":["## Summary"]},{"cell_type":"markdown","metadata":{"id":"omki6mm0fahZ"},"source":["Nesta seção, utilizamos vários novos tipos de camadas para implementar uma CNN, que teve um desempenho melhor do que o modelo mais simples usado na última seção. Esperamos que o processo geral de criação e treinamento de um modelo com dados preparados esteja começando a se tornar ainda mais familiar."]},{"cell_type":"markdown","metadata":{"id":"MHmmxFqxfahZ"},"source":["## Limpando a memória\n","Antes de prosseguir, execute a seguinte célula para limpar a memória da GPU. Isso é necessário para passar para o próximo caderno."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Noz4lGWffahZ"},"outputs":[],"source":["#import IPython\n","#app = IPython.Application.instance()\n","#app.kernel.do_shutdown(True)"]},{"cell_type":"markdown","metadata":{"id":"QilTlVcrfahZ"},"source":["## Próximo"]},{"cell_type":"markdown","metadata":{"id":"XKTvBLF6fahZ"},"source":["Nas últimas seções você se concentrou na criação e no treinamento de modelos. Para melhorar ainda mais o desempenho, agora você voltará sua atenção para o *aumento de dados*, uma coleção de técnicas que permitirá que seus modelos sejam treinados com mais e melhores dados do que aqueles que você poderia ter originalmente à sua disposição."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[{"file_id":"1zDfViplE4wwpZ2fg0cCG4AwBVAt9bp_W","timestamp":1699049007875},{"file_id":"11kbuN2ANLfGNx78SiDNZvi5eWyRsR_t_","timestamp":1699010618773},{"file_id":"1ShNzN2ywKZh0AeqbFQRBHKD7yTOTrKkW","timestamp":1698666609782},{"file_id":"17GNUm8-vpLuRqiydbfDiGR2oqoYR4SHn","timestamp":1664661280620}],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}